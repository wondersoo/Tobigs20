{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fu39oBW0RVn5"
   },
   "source": [
    "# [과제 3] 로지스틱 회귀분석\n",
    "### - sklearn 패키지를 사용해 로지스틱 회귀분석을 진행해주세요.\n",
    "### - 성능지표를 계산하고 이에 대해 해석해주세요.\n",
    "### - 성능 개선을 시도해주세요. (어떠한 성능지표를 기준으로 개선을 시도했는지, 그 이유도 함께 적어주세요.)\n",
    "### - 주석으로 설명 및 근거 자세하게 달아주시면 감사하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rN2SWezRVn_"
   },
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7SYKNvQRVn_"
   },
   "source": [
    "출처 : https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "\n",
    "* V1 ~ V28 : 비식별화 된 개인정보 \n",
    "* **Class** : Target 변수  \n",
    "  - 1 : fraudulent transactions (사기)\n",
    "  - 0 : otherwise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Uvjw2fTCRVoA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "znQit70ZRVoA"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"assignment3_creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220
    },
    "id": "v98OeXW5RVoB",
    "outputId": "42afeddc-07e6-4224-95ee-08b455f72475"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1995, test_size = 0.3, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능지표 계산 함수 만들기\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, confusion_matrix, precision_recall_curve, roc_curve\n",
    "\n",
    "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred)\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_test, pred_proba)\n",
    "    print('오차 행렬 confusion matrix')\n",
    "    print(confusion)\n",
    "    print('정확도 accuracy: {0:.4f}, 정밀도 precision: {1:.4f}, 재현율 recall: {2:.4f}, F1: {3:.4f}, AUC: {4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로지스틱 회귀분석 진행\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "lr_pred_proba = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "get_clf_eval(y_test, lr_pred, lr_pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 해석 \n",
    "* 정확도 (Accuracy): 정확도는 0.9977로, 매우 높은 정확도를 갖고 있다고 볼 수 있습니다.\n",
    "* 정밀도 (Precision): 정밀도는 0.9500으로, Positive로 예측한 것 중 95%가 실제로 Positive라고 할 수 있습니다.\n",
    "* 재현율 (Recall): 재현율은 0.7703으로, 실제 Positive 중 77%를 모델이 정확하게 예측했다고 해석할 수 있습니다.\n",
    "* F1 (F1 Score): F1은 0.8507로, 정밀도와 재현율의 균형있는 성능을 보여줍니다.\n",
    "* AUC: AUC는 0.9712로, 모델의 분류 성능이 좋음을 나타냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복적으로 모델 학습/예측/평가 함수 생성\n",
    "def get_model_train_eval(model, ftr_train=None, ftr_test=None, tgt_train=None, tgt_test=None):\n",
    "    model.fit(ftr_train, tgt_train)\n",
    "    pred = model.predict(ftr_test)\n",
    "    pred_proba = model.predict_proba(ftr_test)[:, 1]\n",
    "    get_clf_eval(tgt_test, pred, pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 개선 시도 : 이상치 제거 \n",
    "\n",
    "# dataframe의 correlation 구한 뒤 heatmap으로 나타내기\n",
    "plt.figure(figsize=(9, 9))\n",
    "corr = data.corr()\n",
    "sns.heatmap(corr, cmap='RdBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class feature와 음의 상관관계가 가장 높은 feature는 V14, V17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V14에 대해서 이상치 제거하기 \n",
    "def get_outlier(data=None,column=None,weight=1.5):\n",
    "    # fraud에 해당하는 column 데이터만 추출, 1사분위와 3사분위 지점을 구함\n",
    "    fraud = data[data['Class'] == 1][column]\n",
    "    quantile_25 = np.percentile(fraud.values, 25)\n",
    "    quantile_75 = np.percentile(fraud.values, 75)\n",
    "    # IQR을 구하고 IQR에 1.5를 곱해 최댓값과 최솟값 지점 구함\n",
    "    iqr = quantile_75 - quantile_25\n",
    "    iqr_weight = iqr * weight\n",
    "    lowest_val = quantile_25 - iqr_weight\n",
    "    highest_val = quantile_75 + iqr_weight\n",
    "    # 이상치 index 반환\n",
    "    outlier_index = fraud[(fraud < lowest_val) | (fraud > highest_val)].index\n",
    "    return outlier_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_index = get_outlier(data=data, column='V14', weight=1.5)\n",
    "print('이상치 데이터 인덱스: ', outlier_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추출된 이상치 제거 후 모델 적용\n",
    "data.drop(outlier_index, axis=0, inplace=True)\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1995, test_size = 0.3, stratify = y)\n",
    "\n",
    "get_model_train_eval(lr, ftr_train = X_train, ftr_test = X_test, tgt_train = y_train, tgt_test = y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Regression_과제3",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
